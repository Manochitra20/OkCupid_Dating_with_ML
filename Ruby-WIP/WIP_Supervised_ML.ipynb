{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import items\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59946"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Raw data file\n",
    "file_to_load = \"user_profiles.csv\"\n",
    "\n",
    "# Read purchasing file and store into pandas data frame\n",
    "df= pd.read_csv(file_to_load)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>height</th>\n",
       "      <th>sex</th>\n",
       "      <th>smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>75.0</td>\n",
       "      <td>m</td>\n",
       "      <td>sometimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>70.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>66.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59941</th>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>62.0</td>\n",
       "      <td>f</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>24</td>\n",
       "      <td>fit</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>72.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>42</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>not at all</td>\n",
       "      <td>never</td>\n",
       "      <td>71.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>27</td>\n",
       "      <td>athletic</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>often</td>\n",
       "      <td>73.0</td>\n",
       "      <td>m</td>\n",
       "      <td>trying to quit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59945</th>\n",
       "      <td>39</td>\n",
       "      <td>average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>m</td>\n",
       "      <td>sometimes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59946 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age       body_type               diet      drinks      drugs  height  \\\n",
       "0       22  a little extra  strictly anything    socially      never    75.0   \n",
       "1       35         average       mostly other       often  sometimes    70.0   \n",
       "2       38            thin           anything    socially        NaN    68.0   \n",
       "3       23            thin         vegetarian    socially        NaN    71.0   \n",
       "4       29        athletic                NaN    socially      never    66.0   \n",
       "...    ...             ...                ...         ...        ...     ...   \n",
       "59941   59             NaN                NaN    socially      never    62.0   \n",
       "59942   24             fit    mostly anything       often  sometimes    72.0   \n",
       "59943   42         average    mostly anything  not at all      never    71.0   \n",
       "59944   27        athletic    mostly anything    socially      often    73.0   \n",
       "59945   39         average                NaN    socially        NaN    68.0   \n",
       "\n",
       "      sex          smokes  \n",
       "0       m       sometimes  \n",
       "1       m              no  \n",
       "2       m              no  \n",
       "3       m              no  \n",
       "4       m              no  \n",
       "...    ..             ...  \n",
       "59941   f              no  \n",
       "59942   m              no  \n",
       "59943   m              no  \n",
       "59944   m  trying to quit  \n",
       "59945   m       sometimes  \n",
       "\n",
       "[59946 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep columns that will assist on determining body type.\n",
    "\n",
    "working_df = df.drop(columns=['sign', 'speaks', 'status', 'last_online', 'income', 'location', 'job', 'education', 'orientation', 'religion', 'ethnicity'])\n",
    "working_df = working_df.drop(columns=['offspring', 'pets', 'Unnamed: 0'])\n",
    "working_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>height</th>\n",
       "      <th>sex</th>\n",
       "      <th>smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>75.0</td>\n",
       "      <td>m</td>\n",
       "      <td>sometimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>70.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>65.0</td>\n",
       "      <td>f</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37</td>\n",
       "      <td>athletic</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>not at all</td>\n",
       "      <td>never</td>\n",
       "      <td>65.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>28</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>72.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59935</th>\n",
       "      <td>33</td>\n",
       "      <td>curvy</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>67.0</td>\n",
       "      <td>f</td>\n",
       "      <td>when drinking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59936</th>\n",
       "      <td>25</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>61.0</td>\n",
       "      <td>f</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>24</td>\n",
       "      <td>fit</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>72.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>42</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>not at all</td>\n",
       "      <td>never</td>\n",
       "      <td>71.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>27</td>\n",
       "      <td>athletic</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>often</td>\n",
       "      <td>73.0</td>\n",
       "      <td>m</td>\n",
       "      <td>trying to quit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25202 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age       body_type               diet      drinks      drugs  height  \\\n",
       "0       22  a little extra  strictly anything    socially      never    75.0   \n",
       "1       35         average       mostly other       often  sometimes    70.0   \n",
       "7       31         average    mostly anything    socially      never    65.0   \n",
       "9       37        athletic    mostly anything  not at all      never    65.0   \n",
       "11      28         average    mostly anything    socially      never    72.0   \n",
       "...    ...             ...                ...         ...        ...     ...   \n",
       "59935   33           curvy           anything    socially      never    67.0   \n",
       "59936   25         average    mostly anything    socially      never    61.0   \n",
       "59942   24             fit    mostly anything       often  sometimes    72.0   \n",
       "59943   42         average    mostly anything  not at all      never    71.0   \n",
       "59944   27        athletic    mostly anything    socially      often    73.0   \n",
       "\n",
       "      sex          smokes  \n",
       "0       m       sometimes  \n",
       "1       m              no  \n",
       "7       f              no  \n",
       "9       m              no  \n",
       "11      m              no  \n",
       "...    ..             ...  \n",
       "59935   f   when drinking  \n",
       "59936   f              no  \n",
       "59942   m              no  \n",
       "59943   m              no  \n",
       "59944   m  trying to quit  \n",
       "\n",
       "[25202 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop NaN values\n",
    "working_df = working_df.dropna()\n",
    "working_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'body_type', 'diet', 'drinks', 'drugs', 'height', 'sex', 'smokes']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See what columns we're working with    \n",
    "\n",
    "list(working_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>height</th>\n",
       "      <th>sex</th>\n",
       "      <th>smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>75.0</td>\n",
       "      <td>m</td>\n",
       "      <td>sometimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>average</td>\n",
       "      <td>other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>70.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31</td>\n",
       "      <td>average</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>65.0</td>\n",
       "      <td>f</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37</td>\n",
       "      <td>athletic</td>\n",
       "      <td>anything</td>\n",
       "      <td>not at all</td>\n",
       "      <td>never</td>\n",
       "      <td>65.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>28</td>\n",
       "      <td>average</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>72.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59935</th>\n",
       "      <td>33</td>\n",
       "      <td>curvy</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>67.0</td>\n",
       "      <td>f</td>\n",
       "      <td>when drinking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59936</th>\n",
       "      <td>25</td>\n",
       "      <td>average</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>61.0</td>\n",
       "      <td>f</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>24</td>\n",
       "      <td>fit</td>\n",
       "      <td>anything</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>72.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>42</td>\n",
       "      <td>average</td>\n",
       "      <td>anything</td>\n",
       "      <td>not at all</td>\n",
       "      <td>never</td>\n",
       "      <td>71.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>27</td>\n",
       "      <td>athletic</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>often</td>\n",
       "      <td>73.0</td>\n",
       "      <td>m</td>\n",
       "      <td>trying to quit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25124 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age       body_type      diet      drinks      drugs  height sex  \\\n",
       "0       22  a little extra  anything    socially      never    75.0   m   \n",
       "1       35         average     other       often  sometimes    70.0   m   \n",
       "7       31         average  anything    socially      never    65.0   f   \n",
       "9       37        athletic  anything  not at all      never    65.0   m   \n",
       "11      28         average  anything    socially      never    72.0   m   \n",
       "...    ...             ...       ...         ...        ...     ...  ..   \n",
       "59935   33           curvy  anything    socially      never    67.0   f   \n",
       "59936   25         average  anything    socially      never    61.0   f   \n",
       "59942   24             fit  anything       often  sometimes    72.0   m   \n",
       "59943   42         average  anything  not at all      never    71.0   m   \n",
       "59944   27        athletic  anything    socially      often    73.0   m   \n",
       "\n",
       "               smokes  \n",
       "0           sometimes  \n",
       "1                  no  \n",
       "7                  no  \n",
       "9                  no  \n",
       "11                 no  \n",
       "...               ...  \n",
       "59935   when drinking  \n",
       "59936              no  \n",
       "59942              no  \n",
       "59943              no  \n",
       "59944  trying to quit  \n",
       "\n",
       "[25124 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove inaccurate ages\n",
    "\n",
    "working_df = working_df[working_df.age != 109]\n",
    "working_df = working_df[working_df.age != 111]\n",
    "\n",
    "# Combine data that makes sense\n",
    "working_df = working_df.replace({'diet':{'strictly anything': 'anything',\n",
    "        'mostly anything': 'anything',\n",
    "        'strictly halal': 'halal',\n",
    "        'mostly halal':'halal',\n",
    "        'strictly kosher': 'kosher',\n",
    "        'mostly kosher':'kosher',\n",
    "        'strictly vegan':'vegan',\n",
    "        'mostly vegan': 'vegan',\n",
    "        'strictly vegetarian':'vegetarian',\n",
    "        'mostly vegetarian':'vegetarian',\n",
    "        'strictly other': 'other',\n",
    "        'mostly other': 'other'}})\n",
    "\n",
    "\n",
    "# Remove values that have declined to answer, since they will be unhelpful        \n",
    "\n",
    "values = ['declined to answer']        \n",
    "\n",
    "working_df = working_df[working_df.age.isin(values) == False]\n",
    "working_df = working_df[working_df.diet.isin(values) == False]\n",
    "working_df = working_df[working_df.body_type.isin(values) == False]\n",
    "working_df = working_df[working_df.drinks.isin(values) == False]\n",
    "working_df = working_df[working_df.drugs.isin(values) == False]\n",
    "working_df = working_df[working_df.height.isin(values) == False]\n",
    "working_df = working_df[working_df.sex.isin(values) == False]\n",
    "working_df = working_df[working_df.smokes.isin(values) == False]\n",
    "working_df = working_df[working_df.body_type != 'rather not say']\n",
    "\n",
    "working_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average           6802\n",
       "fit               5742\n",
       "athletic          5366\n",
       "thin              2191\n",
       "curvy             1843\n",
       "a little extra    1312\n",
       "skinny             804\n",
       "full figured       464\n",
       "overweight         227\n",
       "jacked             191\n",
       "used up            182\n",
       "Name: body_type, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique body type values\n",
    "working_df['body_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit           11299\n",
       "average        6802\n",
       "curvy          3619\n",
       "thin           2995\n",
       "overweight      227\n",
       "used up         182\n",
       "Name: body_type, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up body type values\n",
    "cleaned_BT_df = working_df.replace({'body_type': {'athletic':'fit', 'full figured':'curvy', 'a little extra':'curvy', 'jacked':'fit', 'skinny':'thin'}})\n",
    "cleaned_BT_df['body_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no                20349\n",
       "sometimes          1679\n",
       "when drinking      1425\n",
       "yes                1023\n",
       "trying to quit      648\n",
       "Name: smokes, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique values of diet\n",
    "cleaned_BT_df['smokes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25124, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_BT_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with Target Data = Body Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the dataset into data and target\n",
    "X = cleaned_BT_df.drop(['body_type'], axis=1)\n",
    "y = cleaned_BT_df['body_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 2, 0, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do get dummies for data and label encoder for target\n",
    "X_dummies = pd.get_dummies(X)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "y_label = LabelEncoder().fit_transform(cleaned_BT_df['body_type'])\n",
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dummies, y_label,test_size=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7474924375099506\n",
      "Testing Score: 0.3879955421111288\n"
     ]
    }
   ],
   "source": [
    "# Test with Random Forest to see how well it works\n",
    "\n",
    "RF_clf = RandomForestClassifier(n_estimators=100).fit(X_train, y_train)\n",
    "print(f'Training Score: {RF_clf.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {RF_clf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Random Forest, the Training went pretty well, but the resulting testing score was horrible. Unsure if it's because of the data or if it's because of the model.\n",
    "We'll test it with other models and see how those results pan out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.4556599267632543\n",
      "Testing Data Score: 0.45757045056519663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruby\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Test with Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR_clf = LogisticRegression()\n",
    "\n",
    "LR_clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training Data Score: {LR_clf.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {LR_clf.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Logistic Regression, even though there's more than one target data, just to see how it fares, it results in both training and testing being giving horrible results. This is most likely due to the model being better suited to work with target datas with two values (i.e. \"Yes\" & \"No\")\n",
    "\n",
    "For now, we'll try using Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaler instance\n",
    "import sklearn as skl\n",
    "import tensorflow as tf\n",
    "\n",
    "X_scaler = skl.preprocessing.StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Keras Sequential model\n",
    "nn_model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add our first Dense layer, including the input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"relu\", input_dim=X_train_scaled.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the output layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 5)                 125       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check the structure of the Sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: -0.2672 - accuracy: 0.1559\n",
      "Epoch 2/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: -2.3644 - accuracy: 0.1416\n",
      "Epoch 3/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -5.7213 - accuracy: 0.1415\n",
      "Epoch 4/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -11.4083 - accuracy: 0.1415\n",
      "Epoch 5/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -19.9308 - accuracy: 0.1415\n",
      "Epoch 6/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -31.6715 - accuracy: 0.1415\n",
      "Epoch 7/50\n",
      "393/393 [==============================] - 0s 950us/step - loss: -45.8597 - accuracy: 0.1415\n",
      "Epoch 8/50\n",
      "393/393 [==============================] - 0s 987us/step - loss: -62.1057 - accuracy: 0.1415\n",
      "Epoch 9/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -80.3032 - accuracy: 0.1415\n",
      "Epoch 10/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -100.1370 - accuracy: 0.1415\n",
      "Epoch 11/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -121.6985 - accuracy: 0.1415\n",
      "Epoch 12/50\n",
      "393/393 [==============================] - 0s 990us/step - loss: -144.8818 - accuracy: 0.1415\n",
      "Epoch 13/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -169.6176 - accuracy: 0.1415\n",
      "Epoch 14/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: -195.9285 - accuracy: 0.1415\n",
      "Epoch 15/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: -223.7930 - accuracy: 0.1415\n",
      "Epoch 16/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: -253.2470 - accuracy: 0.1415\n",
      "Epoch 17/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: -284.0888 - accuracy: 0.1415\n",
      "Epoch 18/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -316.4342 - accuracy: 0.1415\n",
      "Epoch 19/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -350.2421 - accuracy: 0.1415\n",
      "Epoch 20/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -385.6368 - accuracy: 0.1415\n",
      "Epoch 21/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -422.5330 - accuracy: 0.1415\n",
      "Epoch 22/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -460.9134 - accuracy: 0.1415\n",
      "Epoch 23/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -500.7142 - accuracy: 0.1415\n",
      "Epoch 24/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -542.1581 - accuracy: 0.1415\n",
      "Epoch 25/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -585.0283 - accuracy: 0.1415\n",
      "Epoch 26/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -629.2148 - accuracy: 0.1415\n",
      "Epoch 27/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: -674.9293 - accuracy: 0.1415\n",
      "Epoch 28/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -722.0413 - accuracy: 0.1415\n",
      "Epoch 29/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -770.5343 - accuracy: 0.1415\n",
      "Epoch 30/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -820.3914 - accuracy: 0.1415\n",
      "Epoch 31/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -871.6146 - accuracy: 0.1415\n",
      "Epoch 32/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -924.3702 - accuracy: 0.1415\n",
      "Epoch 33/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -978.8249 - accuracy: 0.1415\n",
      "Epoch 34/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -1034.6620 - accuracy: 0.1415\n",
      "Epoch 35/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -1092.0745 - accuracy: 0.1415\n",
      "Epoch 36/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -1150.8333 - accuracy: 0.1415\n",
      "Epoch 37/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -1210.9929 - accuracy: 0.1415\n",
      "Epoch 38/50\n",
      "393/393 [==============================] - 1s 2ms/step - loss: -1272.7749 - accuracy: 0.1415\n",
      "Epoch 39/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -1335.6259 - accuracy: 0.1415\n",
      "Epoch 40/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -1399.8971 - accuracy: 0.1415\n",
      "Epoch 41/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -1465.8048 - accuracy: 0.1415\n",
      "Epoch 42/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -1533.2411 - accuracy: 0.1415\n",
      "Epoch 43/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -1602.1046 - accuracy: 0.1415\n",
      "Epoch 44/50\n",
      "393/393 [==============================] - 1s 2ms/step - loss: -1672.6090 - accuracy: 0.1415\n",
      "Epoch 45/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: -1744.4861 - accuracy: 0.1415\n",
      "Epoch 46/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -1818.0167 - accuracy: 0.1415\n",
      "Epoch 47/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -1892.8953 - accuracy: 0.1415\n",
      "Epoch 48/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -1969.0017 - accuracy: 0.1415\n",
      "Epoch 49/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -2046.5699 - accuracy: 0.1415\n",
      "Epoch 50/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: -2125.5769 - accuracy: 0.1415\n"
     ]
    }
   ],
   "source": [
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model to the training data\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So even with the Neural Networking, the score plateau'd and stayed consistently at low accuracy. This is looking more like an issue with the data rather than the models since it's bad with each selected model so far.\n",
    "\n",
    "To switch things up, instead of body types, I'll switch the target data to be the Sex instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the dataset into data and target\n",
    "X = cleaned_BT_df.drop(['sex'], axis=1)\n",
    "y = cleaned_BT_df['sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do get dummies for data and label encoder for target\n",
    "X_dummies = pd.get_dummies(X)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "y_label = LabelEncoder().fit_transform(cleaned_BT_df['sex'])\n",
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dummies, y_label,test_size=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9402165260308868\n",
      "Testing Score: 0.8205699729342462\n"
     ]
    }
   ],
   "source": [
    "# Test with Random Forest to see how well it works\n",
    "\n",
    "RF_clf = RandomForestClassifier(n_estimators=100).fit(X_train, y_train)\n",
    "print(f'Training Score: {RF_clf.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {RF_clf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, the accuracy is great when the models are subjected to pick either Male or Female. Perhaps it's because of it's requiring to pick between two values instead of six? For consistency sake, I'll rerun the other models as well to see if RandomForest's good scores were a fluke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8421429708645121\n",
      "Testing Data Score: 0.8374462665180704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruby\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Test with Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR_clf = LogisticRegression()\n",
    "\n",
    "LR_clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training Data Score: {LR_clf.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {LR_clf.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaler instance\n",
    "import sklearn as skl\n",
    "import tensorflow as tf\n",
    "\n",
    "X_scaler = skl.preprocessing.StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Keras Sequential model\n",
    "nn_model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add our first Dense layer, including the input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"relu\", input_dim=X_train_scaled.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the output layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 5)                 145       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 151\n",
      "Trainable params: 151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check the structure of the Sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.5113 - accuracy: 0.7697\n",
      "Epoch 2/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3911 - accuracy: 0.8327\n",
      "Epoch 3/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3601 - accuracy: 0.8462\n",
      "Epoch 4/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3528 - accuracy: 0.8488\n",
      "Epoch 5/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3501 - accuracy: 0.8509\n",
      "Epoch 6/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3486 - accuracy: 0.8516\n",
      "Epoch 7/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3475 - accuracy: 0.8523\n",
      "Epoch 8/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3467 - accuracy: 0.8514\n",
      "Epoch 9/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3459 - accuracy: 0.8530\n",
      "Epoch 10/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3456 - accuracy: 0.8532\n",
      "Epoch 11/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3453 - accuracy: 0.8523\n",
      "Epoch 12/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3450 - accuracy: 0.8527\n",
      "Epoch 13/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3445 - accuracy: 0.8523\n",
      "Epoch 14/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3441 - accuracy: 0.8531\n",
      "Epoch 15/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3438 - accuracy: 0.8532\n",
      "Epoch 16/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3436 - accuracy: 0.8527\n",
      "Epoch 17/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3435 - accuracy: 0.8534\n",
      "Epoch 18/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3434 - accuracy: 0.8528\n",
      "Epoch 19/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3429 - accuracy: 0.8534\n",
      "Epoch 20/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3428 - accuracy: 0.8542\n",
      "Epoch 21/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3427 - accuracy: 0.8537\n",
      "Epoch 22/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3426 - accuracy: 0.8533\n",
      "Epoch 23/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3423 - accuracy: 0.8544\n",
      "Epoch 24/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3424 - accuracy: 0.8527\n",
      "Epoch 25/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3418 - accuracy: 0.8527\n",
      "Epoch 26/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3419 - accuracy: 0.8541\n",
      "Epoch 27/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3417 - accuracy: 0.8535\n",
      "Epoch 28/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3415 - accuracy: 0.8531\n",
      "Epoch 29/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3413 - accuracy: 0.8534\n",
      "Epoch 30/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3410 - accuracy: 0.8526\n",
      "Epoch 31/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3411 - accuracy: 0.8533\n",
      "Epoch 32/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3406 - accuracy: 0.8529\n",
      "Epoch 33/50\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.3409 - accuracy: 0.8535\n",
      "Epoch 34/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3407 - accuracy: 0.8526\n",
      "Epoch 35/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3410 - accuracy: 0.8542\n",
      "Epoch 36/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3406 - accuracy: 0.8550\n",
      "Epoch 37/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3407 - accuracy: 0.8534\n",
      "Epoch 38/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3406 - accuracy: 0.8543\n",
      "Epoch 39/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3405 - accuracy: 0.8539\n",
      "Epoch 40/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3404 - accuracy: 0.8524\n",
      "Epoch 41/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3403 - accuracy: 0.8547\n",
      "Epoch 42/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3402 - accuracy: 0.8548\n",
      "Epoch 43/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3402 - accuracy: 0.8538\n",
      "Epoch 44/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3401 - accuracy: 0.8535\n",
      "Epoch 45/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3401 - accuracy: 0.8545\n",
      "Epoch 46/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3401 - accuracy: 0.8546\n",
      "Epoch 47/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3399 - accuracy: 0.8545\n",
      "Epoch 48/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3398 - accuracy: 0.8537\n",
      "Epoch 49/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3398 - accuracy: 0.8524\n",
      "Epoch 50/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3397 - accuracy: 0.8550\n"
     ]
    }
   ],
   "source": [
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model to the training data\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our target data being Sex, we managed to have a higher accuracy score for all three models. It's interesting since this having less target values to predict might be better, in correlation with the data we have. With having more target values, in this case the body types, the models we selected did poorly regarding predicting the correct body types. In the future, we might test with more models to see if the there are any that are more compatible with our data, or if we can clean this to be more concise so we can introduce more variables that may help with future predictions."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b06d0177b23106782de6db28b7f0937f65bff3f8af1bbb2d2e40cf7191d9761"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
